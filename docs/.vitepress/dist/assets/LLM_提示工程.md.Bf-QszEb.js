import{_ as e,c as t,o as r,ae as o}from"./chunks/framework.BjlC_BXf.js";const c=JSON.parse('{"title":"提示工程","description":"","frontmatter":{},"headers":[],"relativePath":"LLM/提示工程.md","filePath":"LLM/提示工程.md"}'),n={name:"LLM/提示工程.md"};function i(s,a,h,l,_,d){return r(),t("div",null,a[0]||(a[0]=[o('<h1 id="提示工程" tabindex="-1">提示工程 <a class="header-anchor" href="#提示工程" aria-label="Permalink to &quot;提示工程&quot;">​</a></h1><p>提示词的定义通常涉及到三大要素：<strong>角色、上下文和任务</strong>，如果可以构造好提示词的结构，一般都可以获得比较不错的结果。</p><h3 id="_1-零样本思维链策略" tabindex="-1">1. 零样本思维链策略 <a class="header-anchor" href="#_1-零样本思维链策略" aria-label="Permalink to &quot;1. 零样本思维链策略&quot;">​</a></h3><p>零样本思维链策略：在提示词的末尾添加”<strong>让我们逐步思考</strong>“这样的话。</p><p>为什么这样可以提高模型的性能？</p><p>当我们与大模型进行对话时，模型试图一次性生成我们问题的回答，由于大模型是根据概率来生成文本，对于一些复杂的推理问题，模型生成的文本可能会出现错误的答案。但是，如果我们在提示词中加入”<strong>让我们逐步思考</strong>“这样的话，模型将一步拆分成多步进行推理，逐步生成我们想要的答案。</p><h3 id="_2-少样本学习" tabindex="-1">2. 少样本学习 <a class="header-anchor" href="#_2-少样本学习" aria-label="Permalink to &quot;2. 少样本学习&quot;">​</a></h3><p>少样本学习：在提示词中加入一些示例，告诉模型我们想要的答案的样子。</p><p>为什么这样可以提高模型的性能？</p><p>通过在提示词中加入一些示例，告诉模型我们想要的答案的样子，模型就会根据我们的示例进行学习，从而提高模型的性能。</p><h3 id="_3-指示模型提出更多问题" tabindex="-1">3. 指示模型提出更多问题 <a class="header-anchor" href="#_3-指示模型提出更多问题" aria-label="Permalink to &quot;3. 指示模型提出更多问题&quot;">​</a></h3><p>指示模型提出更多问题：在提示词中加入”<strong>提出更多问题</strong>“这样的话。</p><h3 id="_4-重复提示" tabindex="-1">4. 重复提示 <a class="header-anchor" href="#_4-重复提示" aria-label="Permalink to &quot;4. 重复提示&quot;">​</a></h3><p>当提示词很长时，模型可能会遗忘之前的提示，这时候可以在提示词中加入重复提示，告诉模型我们之前的提示是有用的。</p><h3 id="_5-负面提示" tabindex="-1">5. 负面提示 <a class="header-anchor" href="#_5-负面提示" aria-label="Permalink to &quot;5. 负面提示&quot;">​</a></h3><p>负面提示：在提示词中加入一些与我们想要的答案无关的内容，告诉模型我们不想要的答案。</p><h2 id="持续更新中" tabindex="-1">持续更新中~ <a class="header-anchor" href="#持续更新中" aria-label="Permalink to &quot;持续更新中~&quot;">​</a></h2>',17)]))}const u=e(n,[["render",i]]);export{c as __pageData,u as default};
